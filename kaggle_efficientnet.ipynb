{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-29T12:24:07.881215Z",
     "iopub.status.busy": "2025-11-29T12:24:07.880519Z",
     "iopub.status.idle": "2025-11-29T12:24:24.967820Z",
     "shell.execute_reply": "2025-11-29T12:24:24.966974Z",
     "shell.execute_reply.started": "2025-11-29T12:24:07.881189Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 12:24:09.438648: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764419049.659521      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764419049.722690      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DATA_DIR = \"/kaggle/input/new-dataset-for-efffnet/Final Dataset - Cleaned (1)\"\n",
    "OUTPUT_DIR = \"/kaggle/working/\"\n",
    "IMG_SIZE = (224, 224)  # Paper specifies 224x224\n",
    "BATCH_SIZE = 32\n",
    "VAL_SPLIT = 0.2        # 80/20 split as recommended\n",
    "EPOCHS_HEAD = 10       # Phase 1: Train head\n",
    "EPOCHS_FINE = 15       # Phase 2: Fine-tune all\n",
    "NUM_CLASSES = 124\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T08:52:06.189499Z",
     "iopub.status.busy": "2025-11-29T08:52:06.188752Z",
     "iopub.status.idle": "2025-11-29T08:52:11.196885Z",
     "shell.execute_reply": "2025-11-29T08:52:11.196109Z",
     "shell.execute_reply.started": "2025-11-29T08:52:06.189472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "a2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\n",
      "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\n",
      "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0minstalled\n"
     ]
    }
   ],
   "source": [
    "!pip install \"protobuf==3.20.3\" --quiet\n",
    "print('installed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:24:35.575885Z",
     "iopub.status.busy": "2025-11-29T12:24:35.575221Z",
     "iopub.status.idle": "2025-11-29T12:24:48.961966Z",
     "shell.execute_reply": "2025-11-29T12:24:48.961368Z",
     "shell.execute_reply.started": "2025-11-29T12:24:35.575854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Found 14051 images belonging to 124 classes.\n",
      "Found 3449 images belonging to 124 classes.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. DATA AUGMENTATION (Paper Implementation) ---\n",
    "# The paper explicitly uses Random Cropping, Horizontal Flipping, and Vertical Flipping\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,   # Simulates random cropping when combined with zoom\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,          # Simulates random cropping\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,      # Explicitly mentioned in Alam et al. (2025)\n",
    "    fill_mode='nearest',\n",
    "    validation_split=VAL_SPLIT\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=VAL_SPLIT\n",
    ")\n",
    "\n",
    "# Load Data\n",
    "print(\"Loading data...\")\n",
    "train_flow = train_datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_flow = val_datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    seed=42,\n",
    "    shuffle=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:25:00.849333Z",
     "iopub.status.busy": "2025-11-29T12:25:00.848734Z",
     "iopub.status.idle": "2025-11-29T12:25:00.856168Z",
     "shell.execute_reply": "2025-11-29T12:25:00.855536Z",
     "shell.execute_reply.started": "2025-11-29T12:25:00.849306Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights computed for 124 classes.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. CLASS WEIGHTS (Handle Imbalance) ---\n",
    "class_weights_arr = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_flow.classes),\n",
    "    y=train_flow.classes\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights_arr))\n",
    "print(f\"Class weights computed for {len(class_weights_dict)} classes.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:25:10.240171Z",
     "iopub.status.busy": "2025-11-29T12:25:10.239349Z",
     "iopub.status.idle": "2025-11-29T12:25:13.818733Z",
     "shell.execute_reply": "2025-11-29T12:25:13.817937Z",
     "shell.execute_reply.started": "2025-11-29T12:25:10.240139Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1764419111.111675      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1764419111.112295      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# --- 3. BUILD MODEL (EfficientNetB0) ---\n",
    "def build_model(num_classes):\n",
    "    # Load EfficientNetB0 pre-trained on ImageNet\n",
    "    base_model = EfficientNetB0(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    "    )\n",
    "\n",
    "    # Freeze base model initially (Phase 1)\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Paper uses a standard classifier head approach\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=base_model.input, outputs=outputs)\n",
    "    return model, base_model\n",
    "\n",
    "model, base_model = build_model(NUM_CLASSES)\n",
    "\n",
    "# Metrics: Top-1 and Top-5 Accuracy\n",
    "metrics_list = [\n",
    "    'accuracy',\n",
    "    tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top_5_accuracy')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T10:41:22.207502Z",
     "iopub.status.busy": "2025-11-29T10:41:22.207220Z",
     "iopub.status.idle": "2025-11-29T11:39:44.396741Z",
     "shell.execute_reply": "2025-11-29T11:39:44.395867Z",
     "shell.execute_reply.started": "2025-11-29T10:41:22.207481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase 1: Training Classifier Head (Frozen Backbone) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1764412894.394967     129 service.cc:148] XLA service 0x7be590002be0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1764412894.395818     129 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1764412894.395842     129 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1764412896.357881     129 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  2/440\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 52ms/step - accuracy: 0.0078 - loss: 6.9412 - top_5_accuracy: 0.0312       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1764412905.914421     129 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 29/440\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:25\u001b[0m 1s/step - accuracy: 0.0166 - loss: 5.8105 - top_5_accuracy: 0.0587"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868ms/step - accuracy: 0.2605 - loss: 3.4105 - top_5_accuracy: 0.4836"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 2. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.65874, saving model to /kaggle/working/best_model_phase1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 1s/step - accuracy: 0.2608 - loss: 3.4082 - top_5_accuracy: 0.4841 - val_accuracy: 0.6587 - val_loss: 1.3022 - val_top_5_accuracy: 0.8800\n",
      "Epoch 2/10\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669ms/step - accuracy: 0.6306 - loss: 1.2977 - top_5_accuracy: 0.8860\n",
      "Epoch 2: val_accuracy improved from 0.65874 to 0.68716, saving model to /kaggle/working/best_model_phase1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 768ms/step - accuracy: 0.6306 - loss: 1.2977 - top_5_accuracy: 0.8860 - val_accuracy: 0.6872 - val_loss: 1.1659 - val_top_5_accuracy: 0.9037\n",
      "Epoch 3/10\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661ms/step - accuracy: 0.6908 - loss: 1.0223 - top_5_accuracy: 0.9174\n",
      "Epoch 3: val_accuracy improved from 0.68716 to 0.71499, saving model to /kaggle/working/best_model_phase1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 762ms/step - accuracy: 0.6908 - loss: 1.0224 - top_5_accuracy: 0.9174 - val_accuracy: 0.7150 - val_loss: 1.0865 - val_top_5_accuracy: 0.9159\n",
      "Epoch 4/10\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668ms/step - accuracy: 0.7207 - loss: 0.8937 - top_5_accuracy: 0.9368\n",
      "Epoch 4: val_accuracy improved from 0.71499 to 0.72050, saving model to /kaggle/working/best_model_phase1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 769ms/step - accuracy: 0.7207 - loss: 0.8938 - top_5_accuracy: 0.9368 - val_accuracy: 0.7205 - val_loss: 1.0907 - val_top_5_accuracy: 0.9133\n",
      "Epoch 5/10\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663ms/step - accuracy: 0.7510 - loss: 0.8030 - top_5_accuracy: 0.9489\n",
      "Epoch 5: val_accuracy did not improve from 0.72050\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 764ms/step - accuracy: 0.7509 - loss: 0.8030 - top_5_accuracy: 0.9488 - val_accuracy: 0.7202 - val_loss: 1.0960 - val_top_5_accuracy: 0.9162\n",
      "Epoch 6/10\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666ms/step - accuracy: 0.7573 - loss: 0.7509 - top_5_accuracy: 0.9493\n",
      "Epoch 6: val_accuracy improved from 0.72050 to 0.74224, saving model to /kaggle/working/best_model_phase1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 766ms/step - accuracy: 0.7573 - loss: 0.7510 - top_5_accuracy: 0.9492 - val_accuracy: 0.7422 - val_loss: 1.0556 - val_top_5_accuracy: 0.9243\n",
      "Epoch 7/10\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667ms/step - accuracy: 0.7688 - loss: 0.7151 - top_5_accuracy: 0.9563\n",
      "Epoch 7: val_accuracy did not improve from 0.74224\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 764ms/step - accuracy: 0.7688 - loss: 0.7152 - top_5_accuracy: 0.9563 - val_accuracy: 0.7376 - val_loss: 1.0385 - val_top_5_accuracy: 0.9255\n",
      "Epoch 8/10\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660ms/step - accuracy: 0.7736 - loss: 0.6931 - top_5_accuracy: 0.9568\n",
      "Epoch 8: val_accuracy did not improve from 0.74224\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 758ms/step - accuracy: 0.7736 - loss: 0.6932 - top_5_accuracy: 0.9568 - val_accuracy: 0.7399 - val_loss: 1.0528 - val_top_5_accuracy: 0.9290\n",
      "Epoch 9/10\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662ms/step - accuracy: 0.7815 - loss: 0.6800 - top_5_accuracy: 0.9624\n",
      "Epoch 9: val_accuracy improved from 0.74224 to 0.74456, saving model to /kaggle/working/best_model_phase1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 757ms/step - accuracy: 0.7815 - loss: 0.6800 - top_5_accuracy: 0.9624 - val_accuracy: 0.7446 - val_loss: 1.0573 - val_top_5_accuracy: 0.9220\n",
      "Epoch 10/10\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662ms/step - accuracy: 0.7903 - loss: 0.6513 - top_5_accuracy: 0.9636\n",
      "Epoch 10: val_accuracy improved from 0.74456 to 0.74775, saving model to /kaggle/working/best_model_phase1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 760ms/step - accuracy: 0.7903 - loss: 0.6514 - top_5_accuracy: 0.9636 - val_accuracy: 0.7478 - val_loss: 1.0394 - val_top_5_accuracy: 0.9301\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    }
   ],
   "source": [
    "# --- 4. PHASE 1: TRAIN HEAD ONLY ---\n",
    "print(\"\\n--- Phase 1: Training Classifier Head (Frozen Backbone) ---\")\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=metrics_list\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        os.path.join(OUTPUT_DIR, \"best_model_phase1.h5\"),\n",
    "        monitor='val_accuracy', save_best_only=True, verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=3, restore_best_weights=True, verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history_phase1 = model.fit(\n",
    "    train_flow,\n",
    "    epochs=EPOCHS_HEAD,\n",
    "    validation_data=val_flow,\n",
    "    class_weight=class_weights_dict,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:48:16.444715Z",
     "iopub.status.busy": "2025-11-29T12:48:16.444028Z",
     "iopub.status.idle": "2025-11-29T14:16:36.347413Z",
     "shell.execute_reply": "2025-11-29T14:16:36.346842Z",
     "shell.execute_reply.started": "2025-11-29T12:48:16.444688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase 2: Fine-Tuning Entire Network ---\n",
      "Epoch 1/15\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754ms/step - accuracy: 0.1103 - loss: 4.1584 - top_5_accuracy: 0.2751\n",
      "Epoch 1: val_accuracy improved from -inf to 0.23253, saving model to /kaggle/working/best_model_final.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 878ms/step - accuracy: 0.1103 - loss: 4.1581 - top_5_accuracy: 0.2752 - val_accuracy: 0.2325 - val_loss: 3.5391 - val_top_5_accuracy: 0.4494 - learning_rate: 1.0000e-05\n",
      "Epoch 2/15\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705ms/step - accuracy: 0.1704 - loss: 3.6798 - top_5_accuracy: 0.3940\n",
      "Epoch 2: val_accuracy improved from 0.23253 to 0.31110, saving model to /kaggle/working/best_model_final.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 812ms/step - accuracy: 0.1705 - loss: 3.6796 - top_5_accuracy: 0.3941 - val_accuracy: 0.3111 - val_loss: 3.0950 - val_top_5_accuracy: 0.5544 - learning_rate: 1.0000e-05\n",
      "Epoch 3/15\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736ms/step - accuracy: 0.2430 - loss: 3.2297 - top_5_accuracy: 0.4956\n",
      "Epoch 3: val_accuracy improved from 0.31110 to 0.36590, saving model to /kaggle/working/best_model_final.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 835ms/step - accuracy: 0.2430 - loss: 3.2295 - top_5_accuracy: 0.4957 - val_accuracy: 0.3659 - val_loss: 2.7352 - val_top_5_accuracy: 0.6367 - learning_rate: 1.0000e-05\n",
      "Epoch 4/15\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684ms/step - accuracy: 0.3012 - loss: 2.8820 - top_5_accuracy: 0.5758\n",
      "Epoch 4: val_accuracy improved from 0.36590 to 0.41867, saving model to /kaggle/working/best_model_final.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 785ms/step - accuracy: 0.3012 - loss: 2.8819 - top_5_accuracy: 0.5759 - val_accuracy: 0.4187 - val_loss: 2.4451 - val_top_5_accuracy: 0.7025 - learning_rate: 1.0000e-05\n",
      "Epoch 5/15\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692ms/step - accuracy: 0.3459 - loss: 2.6022 - top_5_accuracy: 0.6427\n",
      "Epoch 5: val_accuracy improved from 0.41867 to 0.46999, saving model to /kaggle/working/best_model_final.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 791ms/step - accuracy: 0.3459 - loss: 2.6021 - top_5_accuracy: 0.6427 - val_accuracy: 0.4700 - val_loss: 2.1969 - val_top_5_accuracy: 0.7483 - learning_rate: 1.0000e-05\n",
      "Epoch 6/15\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686ms/step - accuracy: 0.4019 - loss: 2.3629 - top_5_accuracy: 0.6901\n",
      "Epoch 6: val_accuracy improved from 0.46999 to 0.50710, saving model to /kaggle/working/best_model_final.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 788ms/step - accuracy: 0.4019 - loss: 2.3628 - top_5_accuracy: 0.6902 - val_accuracy: 0.5071 - val_loss: 2.0051 - val_top_5_accuracy: 0.7796 - learning_rate: 1.0000e-05\n",
      "Epoch 7/15\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679ms/step - accuracy: 0.4478 - loss: 2.1371 - top_5_accuracy: 0.7411\n",
      "Epoch 7: val_accuracy improved from 0.50710 to 0.53871, saving model to /kaggle/working/best_model_final.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 779ms/step - accuracy: 0.4478 - loss: 2.1370 - top_5_accuracy: 0.7411 - val_accuracy: 0.5387 - val_loss: 1.8478 - val_top_5_accuracy: 0.8043 - learning_rate: 1.0000e-05\n",
      "Epoch 8/15\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673ms/step - accuracy: 0.4830 - loss: 1.9704 - top_5_accuracy: 0.7720\n",
      "Epoch 8: val_accuracy improved from 0.53871 to 0.56886, saving model to /kaggle/working/best_model_final.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 770ms/step - accuracy: 0.4830 - loss: 1.9703 - top_5_accuracy: 0.7720 - val_accuracy: 0.5689 - val_loss: 1.7240 - val_top_5_accuracy: 0.8217 - learning_rate: 1.0000e-05\n",
      "Epoch 9/15\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671ms/step - accuracy: 0.5147 - loss: 1.8256 - top_5_accuracy: 0.8070\n",
      "Epoch 9: val_accuracy improved from 0.56886 to 0.58974, saving model to /kaggle/working/best_model_final.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 769ms/step - accuracy: 0.5147 - loss: 1.8256 - top_5_accuracy: 0.8070 - val_accuracy: 0.5897 - val_loss: 1.6159 - val_top_5_accuracy: 0.8391 - learning_rate: 1.0000e-05\n",
      "Epoch 10/15\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657ms/step - accuracy: 0.5301 - loss: 1.7195 - top_5_accuracy: 0.8229\n",
      "Epoch 10: val_accuracy improved from 0.58974 to 0.61409, saving model to /kaggle/working/best_model_final.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 755ms/step - accuracy: 0.5302 - loss: 1.7195 - top_5_accuracy: 0.8229 - val_accuracy: 0.6141 - val_loss: 1.5227 - val_top_5_accuracy: 0.8510 - learning_rate: 1.0000e-05\n",
      "Epoch 11/15\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674ms/step - accuracy: 0.5673 - loss: 1.5781 - top_5_accuracy: 0.8469\n",
      "Epoch 11: val_accuracy improved from 0.61409 to 0.63468, saving model to /kaggle/working/best_model_final.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 773ms/step - accuracy: 0.5673 - loss: 1.5781 - top_5_accuracy: 0.8469 - val_accuracy: 0.6347 - val_loss: 1.4427 - val_top_5_accuracy: 0.8637 - learning_rate: 1.0000e-05\n",
      "Epoch 12/15\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667ms/step - accuracy: 0.5924 - loss: 1.4981 - top_5_accuracy: 0.8560\n",
      "Epoch 12: val_accuracy improved from 0.63468 to 0.64888, saving model to /kaggle/working/best_model_final.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 770ms/step - accuracy: 0.5924 - loss: 1.4981 - top_5_accuracy: 0.8560 - val_accuracy: 0.6489 - val_loss: 1.3778 - val_top_5_accuracy: 0.8698 - learning_rate: 1.0000e-05\n",
      "Epoch 13/15\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677ms/step - accuracy: 0.6103 - loss: 1.3858 - top_5_accuracy: 0.8724\n",
      "Epoch 13: val_accuracy improved from 0.64888 to 0.65729, saving model to /kaggle/working/best_model_final.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 776ms/step - accuracy: 0.6103 - loss: 1.3859 - top_5_accuracy: 0.8724 - val_accuracy: 0.6573 - val_loss: 1.3169 - val_top_5_accuracy: 0.8791 - learning_rate: 1.0000e-05\n",
      "Epoch 14/15\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680ms/step - accuracy: 0.6259 - loss: 1.3679 - top_5_accuracy: 0.8792\n",
      "Epoch 14: val_accuracy improved from 0.65729 to 0.67150, saving model to /kaggle/working/best_model_final.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 788ms/step - accuracy: 0.6259 - loss: 1.3679 - top_5_accuracy: 0.8793 - val_accuracy: 0.6715 - val_loss: 1.2713 - val_top_5_accuracy: 0.8875 - learning_rate: 1.0000e-05\n",
      "Epoch 15/15\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723ms/step - accuracy: 0.6401 - loss: 1.2749 - top_5_accuracy: 0.8933\n",
      "Epoch 15: val_accuracy improved from 0.67150 to 0.68136, saving model to /kaggle/working/best_model_final.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 826ms/step - accuracy: 0.6401 - loss: 1.2749 - top_5_accuracy: 0.8933 - val_accuracy: 0.6814 - val_loss: 1.2321 - val_top_5_accuracy: 0.8916 - learning_rate: 1.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 15.\n"
     ]
    }
   ],
   "source": [
    "# --- 5. PHASE 2: FINE-TUNE ENTIRE NETWORK ---\n",
    "# The paper highlights fine-tuning the *entire network* after head stabilization\n",
    "print(\"\\n--- Phase 2: Fine-Tuning Entire Network ---\")\n",
    "\n",
    "base_model.trainable = True # Unfreeze all layers\n",
    "\n",
    "# Recompile with very low learning rate to prevent destroying learned weights\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-5), # Low LR is critical here\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=metrics_list\n",
    ")\n",
    "\n",
    "callbacks_ft = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        os.path.join(OUTPUT_DIR, \"best_model_final.h5\"),\n",
    "        monitor='val_accuracy', save_best_only=True, verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.5, patience=2, min_lr=1e-7, verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history_phase2 = model.fit(\n",
    "    train_flow,\n",
    "    epochs=EPOCHS_FINE,\n",
    "    validation_data=val_flow,\n",
    "    class_weight=class_weights_dict,\n",
    "    callbacks=callbacks_ft\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T14:19:37.719753Z",
     "iopub.status.busy": "2025-11-29T14:19:37.719014Z",
     "iopub.status.idle": "2025-11-29T14:20:22.056425Z",
     "shell.execute_reply": "2025-11-29T14:20:22.055578Z",
     "shell.execute_reply.started": "2025-11-29T14:19:37.719707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Evaluation ---\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 397ms/step - accuracy: 0.6649 - loss: 1.2737 - top_5_accuracy: 0.8903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Accuracy: 68.14%\n",
      "Final Top-5 Accuracy: 89.16%\n",
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- 6. EVALUATION ---\n",
    "print(\"\\n--- Final Evaluation ---\")\n",
    "# Load the absolute best model from training\n",
    "if os.path.exists(os.path.join(OUTPUT_DIR, \"best_model_final.h5\")):\n",
    "    model.load_weights(os.path.join(OUTPUT_DIR, \"best_model_final.h5\"))\n",
    "\n",
    "results = model.evaluate(val_flow)\n",
    "print(f\"Final Validation Accuracy: {results[1]*100:.2f}%\")\n",
    "print(f\"Final Top-5 Accuracy: {results[2]*100:.2f}%\")\n",
    "\n",
    "# Save in format for inference\n",
    "model.save(os.path.join(OUTPUT_DIR, \"efficientnet_food_model.h5\"))\n",
    "print(\"Model saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8867831,
     "sourceId": 13917118,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
